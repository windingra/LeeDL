{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 10801861,
          "sourceType": "datasetVersion",
          "datasetId": 6704380
        }
      ],
      "dockerImageVersionId": 30887,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aaricis/Hung-yi-Lee-ML2022/blob/main/HW2/HW02_boss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Homework 2: Phoneme Classification**\n"
      ],
      "metadata": {
        "id": "OYlaRwNu7ojq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objectives:\n",
        "* Solve a classification problem with deep neural networks (DNNs).\n",
        "* Understand recursive neural networks (RNNs).\n",
        "\n",
        "If you have any questions, please contact the TAs via TA hours, NTU COOL, or email to mlta-2023-spring@googlegroups.com"
      ],
      "metadata": {
        "id": "A7DRC5V7_8A5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Boss Bseline\n",
        "Score: 0.83055\n",
        "Private score: 0.83148\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "åŠ©æ•™æç¤ºä½¿ç”¨RNNæ¨¡å‹ï¼Œå¯ä»¥ä½¿ç”¨Pytorchçš„`nn.LSTM`ã€`nn.GRU`ã€`nn.RNN`ç­‰æ¨¡å‹ã€‚\n",
        "\n",
        "|  æ¨¡å‹    |  å‚æ•°    |  acc    |\n",
        "| ---- | ---- | ---- |\n",
        "|  RNN    |   é»˜è®¤   |   0.445   |\n",
        "|  RNN    |   concat_nframes = 21 hidden_layers = 3 hidden_dim = 256 * 3 num_epoch = 5|  0.739    |\n",
        "|  RNN    |   concat_nframes = 21 hidden_layers = 4 hidden_dim = 256 * 3 num_epoch = 5|  0.743    |\n",
        "|  LSTM    |   concat_nframes = 21 hidden_layers = 3 hidden_dim = 256 * 3 num_epoch = 5|  0.744   |\n",
        "|  BiLSTM + MLP  |   concat_nframes = 61 hidden_layers = 6 hidden_dim = 256 * 4 num_epoch = 15|  0.82340    |\n",
        "|      |      |      |\n",
        "\n",
        "ä¸€å¼€å§‹å°è¯•å•çº¯çš„RNNå’ŒLSTMï¼Œéƒ½æ²¡æœ‰è·å¾—å¥½çš„æ•ˆæœã€‚åæ¥å°è¯•BiLSTM + MLPæ¨¡å‹ï¼Œå¹¶ä¸”æ˜¾è‘—å¢å¤§å„è®­ç»ƒå‚æ•°çš„å€¼ï¼Œå°±å¯ä»¥è¾¾åˆ°Boss Bselineäº†ã€‚ä¸€åœˆè¯•ä¸‹æ¥ï¼Œè¿™ä¸ªtaskå°±æ˜¯â€œåŠ›å¤§ç –é£â€ï¼Œä½¿åŠ²å¢å¤§è¾“å…¥æ•°æ®ç»´åº¦å’Œè¶…å‚æ•°å°±ğŸ†—äº†ã€‚\n"
      ],
      "metadata": {
        "id": "HPD8exnNyfDB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Data\n",
        "Download data from google drive, then unzip it.\n",
        "\n",
        "You should have\n",
        "- `libriphone/train_split.txt`: training metadata\n",
        "- `libriphone/train_labels`: training labels\n",
        "- `libriphone/test_split.txt`: testing metadata\n",
        "- `libriphone/feat/train/*.pt`: training feature\n",
        "- `libriphone/feat/test/*.pt`:  testing feature\n",
        "\n",
        "after running the following block.\n",
        "\n",
        "> **Notes: if the google drive link is dead, you can download the data directly from [Kaggle](https://www.kaggle.com/c/ml2023spring-hw2/data) and upload it to the workspace.**\n"
      ],
      "metadata": {
        "id": "KVUGfWTo7_Oj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Main link\n",
        "!wget -O libriphone.zip \"https://github.com/xraychen/shiny-robot/releases/download/v1.0/libriphone.zip\"\n",
        "\n",
        "# Backup Link 0\n",
        "# !pip install --upgrade gdown\n",
        "# !gdown --id '1o6Ag-G3qItSmYhTheX6DYiuyNzWyHyTc' --output libriphone.zip\n",
        "\n",
        "# Backup link 1\n",
        "# !pip install --upgrade gdown\n",
        "# !gdown --id '1R1uQYi4QpX0tBfUWt2mbZcncdBsJkxeW' --output libriphone.zip\n",
        "\n",
        "# Backup link 2\n",
        "# !wget -O libriphone.zip \"https://www.dropbox.com/s/wqww8c5dbrl2ka9/libriphone.zip?dl=1\"\n",
        "\n",
        "# Backup link 3\n",
        "# !wget -O libriphone.zip \"https://www.dropbox.com/s/p2ljbtb2bam13in/libriphone.zip?dl=1\"\n",
        "\n",
        "!unzip -q libriphone.zip\n",
        "!ls libriphone"
      ],
      "metadata": {
        "id": "OzkiMEcC3Foq",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-20T08:06:21.003313Z",
          "iopub.execute_input": "2025-02-20T08:06:21.003627Z",
          "iopub.status.idle": "2025-02-20T08:06:39.941845Z",
          "shell.execute_reply.started": "2025-02-20T08:06:21.003588Z",
          "shell.execute_reply": "2025-02-20T08:06:39.940961Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0363bb06-3a9b-4a82-d44f-fae60e864a96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-21 07:48:24--  https://github.com/xraychen/shiny-robot/releases/download/v1.0/libriphone.zip\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/463868124/343908dd-b2e4-4b8e-b7d6-7f0f040179ce?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250221%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250221T074825Z&X-Amz-Expires=300&X-Amz-Signature=26618cd3966cc28b00d3ad84fd277be1db1719b3da89e2cb8725440652df66af&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dlibriphone.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-02-21 07:48:25--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/463868124/343908dd-b2e4-4b8e-b7d6-7f0f040179ce?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250221%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250221T074825Z&X-Amz-Expires=300&X-Amz-Signature=26618cd3966cc28b00d3ad84fd277be1db1719b3da89e2cb8725440652df66af&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dlibriphone.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 478737370 (457M) [application/octet-stream]\n",
            "Saving to: â€˜libriphone.zipâ€™\n",
            "\n",
            "libriphone.zip      100%[===================>] 456.56M  37.6MB/s    in 13s     \n",
            "\n",
            "2025-02-21 07:48:39 (34.9 MB/s) - â€˜libriphone.zipâ€™ saved [478737370/478737370]\n",
            "\n",
            "feat  test_split.txt  train_labels.txt\ttrain_split.txt\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some Utility Functions\n",
        "**Fixes random number generator seeds for reproducibility.**"
      ],
      "metadata": {
        "id": "pADUiYODJE1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "\n",
        "def same_seeds(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "BsZKgBZQJjaE",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-20T07:55:26.050464Z",
          "iopub.execute_input": "2025-02-20T07:55:26.050675Z",
          "iopub.status.idle": "2025-02-20T07:55:29.222953Z",
          "shell.execute_reply.started": "2025-02-20T07:55:26.050654Z",
          "shell.execute_reply": "2025-02-20T07:55:29.222018Z"
        }
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Helper functions to pre-process the training data from raw MFCC features of each utterance.**\n",
        "\n",
        "A phoneme may span several frames and is dependent to past and future frames. \\\n",
        "Hence we concatenate neighboring phonemes for training to achieve higher accuracy. The **concat_feat** function concatenates past and future k frames (total 2k+1 = n frames), and we predict the center frame.\n",
        "\n",
        "Feel free to modify the data preprocess functions, but **do not drop any frame** (if you modify the functions, remember to check that the number of frames are the same as mentioned in the slides)"
      ],
      "metadata": {
        "id": "_L_4anls8Drv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "def load_feat(path):\n",
        "    feat = torch.load(path)\t# å¯¼å…¥éŸ³é¢‘æ–‡ä»¶\n",
        "    return feat\n",
        "\n",
        "def shift(x, n):\n",
        "    # å¹³ç§»æ•°æ®\n",
        "    if n < 0:\n",
        "        left = x[0].repeat(-n, 1)\n",
        "        right = x[:n]\n",
        "    elif n > 0:\n",
        "        right = x[-1].repeat(n, 1)\n",
        "        left = x[n:]\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "    return torch.cat((left, right), dim=0)\n",
        "\n",
        "def concat_feat(x, concat_n):\n",
        "    assert concat_n % 2 == 1 # n must be odd\n",
        "    if concat_n < 2:\n",
        "        return x\n",
        "    seq_len, feature_dim = x.size(0), x.size(1)\n",
        "    x = x.repeat(1, concat_n)\n",
        "    x = x.view(seq_len, concat_n, feature_dim).permute(1, 0, 2) # concat_n, seq_len, feature_dim\n",
        "    mid = (concat_n // 2)\n",
        "    for r_idx in range(1, mid+1):\n",
        "        x[mid + r_idx, :] = shift(x[mid + r_idx], r_idx)\n",
        "        x[mid - r_idx, :] = shift(x[mid - r_idx], -r_idx)\n",
        "\n",
        "    return x.permute(1, 0, 2).view(seq_len, concat_n * feature_dim)\n",
        "\n",
        "def preprocess_data(split, feat_dir, phone_path, concat_nframes, train_ratio=0.8, random_seed=1213):\n",
        "    class_num = 41 # NOTE: pre-computed, should not need change\n",
        "\n",
        "    if split == 'train' or split == 'val':\n",
        "        mode = 'train'\n",
        "    elif split == 'test':\n",
        "        mode = 'test'\n",
        "    else:\n",
        "        raise ValueError('Invalid \\'split\\' argument for dataset: PhoneDataset!')\n",
        "\n",
        "    label_dict = {}\n",
        "    if mode == 'train':\n",
        "        for line in open(os.path.join(phone_path, f'{mode}_labels.txt')).readlines():\n",
        "            line = line.strip('\\n').split(' ')\n",
        "            label_dict[line[0]] = [int(p) for p in line[1:]]\n",
        "\n",
        "        # split training and validation data\n",
        "        usage_list = open(os.path.join(phone_path, 'train_split.txt')).readlines()\n",
        "        random.seed(random_seed)\n",
        "        random.shuffle(usage_list)\n",
        "        train_len = int(len(usage_list) * train_ratio)\n",
        "        usage_list = usage_list[:train_len] if split == 'train' else usage_list[train_len:]\n",
        "\n",
        "    elif mode == 'test':\n",
        "        usage_list = open(os.path.join(phone_path, 'test_split.txt')).readlines()\n",
        "\n",
        "    usage_list = [line.strip('\\n') for line in usage_list]\n",
        "    print('[Dataset] - # phone classes: ' + str(class_num) + ', number of utterances for ' + split + ': ' + str(len(usage_list)))\n",
        "\n",
        "    max_len = 3000000\n",
        "    X = torch.empty(max_len, 39 * concat_nframes)\n",
        "    if mode == 'train':\n",
        "        y = torch.empty(max_len, dtype=torch.long)\n",
        "\n",
        "    idx = 0\n",
        "    for i, fname in tqdm(enumerate(usage_list)):\n",
        "        feat = load_feat(os.path.join(feat_dir, mode, f'{fname}.pt'))\n",
        "        cur_len = len(feat)\n",
        "        feat = concat_feat(feat, concat_nframes)\n",
        "        if mode == 'train':\n",
        "            label = torch.LongTensor(label_dict[fname])\n",
        "\n",
        "        X[idx: idx + cur_len, :] = feat\n",
        "        if mode == 'train':\n",
        "            y[idx: idx + cur_len] = label\n",
        "\n",
        "        idx += cur_len\n",
        "\n",
        "    X = X[:idx, :]\n",
        "    if mode == 'train':\n",
        "        y = y[:idx]\n",
        "\n",
        "    print(f'[INFO] {split} set')\n",
        "    print(X.shape)\n",
        "    if mode == 'train':\n",
        "        print(y.shape)\n",
        "        return X, y\n",
        "    else:\n",
        "        return X"
      ],
      "metadata": {
        "id": "IJjLT8em-y9G",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-20T08:14:15.754659Z",
          "iopub.execute_input": "2025-02-20T08:14:15.755063Z",
          "iopub.status.idle": "2025-02-20T08:14:15.768264Z",
          "shell.execute_reply.started": "2025-02-20T08:14:15.755036Z",
          "shell.execute_reply": "2025-02-20T08:14:15.767377Z"
        }
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "us5XW_x6udZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class LibriDataset(Dataset):\n",
        "    def __init__(self, X, y=None):\n",
        "        self.data = X\n",
        "        if y is not None:\n",
        "            self.label = torch.LongTensor(y)\n",
        "        else:\n",
        "            self.label = None\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.label is not None:\n",
        "            return self.data[idx], self.label[idx]\n",
        "        else:\n",
        "            return self.data[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n"
      ],
      "metadata": {
        "id": "Fjf5EcmJtf4e",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-20T08:14:22.578675Z",
          "iopub.execute_input": "2025-02-20T08:14:22.579002Z",
          "iopub.status.idle": "2025-02-20T08:14:22.584231Z",
          "shell.execute_reply.started": "2025-02-20T08:14:22.578978Z",
          "shell.execute_reply": "2025-02-20T08:14:22.583397Z"
        }
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model\n",
        "Feel free to modify the structure of the model."
      ],
      "metadata": {
        "id": "IRqKNvNZwe3V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## åŒå‘LSTM"
      ],
      "metadata": {
        "id": "MTE7dZbvW7rR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(BasicBlock, self).__init__()\n",
        "\n",
        "        # TODO: apply batch normalization and dropout for strong baseline.\n",
        "        # Reference: https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html (batch normalization)\n",
        "        #       https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html (dropout)\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Linear(input_dim, output_dim),\n",
        "            nn.BatchNorm1d(output_dim),\n",
        "            nn.ReLU(),\n",
        "            # åœ¨æ­¤å¤„å¢åŠ  nn.Dropout()\n",
        "            nn.Dropout(p=0.15)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# TODO: åš Boss baseline å†å–æ¶ˆæ³¨é‡Š\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim=41, hidden_layers=1, hidden_dim=256):\n",
        "        super(Classifier, self).__init__()\n",
        "\n",
        "        # TODO: æ­¤æ—¶æ¨¡å‹è¶…å‚æ•°åœ¨è¿™é‡Œä¿®æ”¹\n",
        "        # Create BiLSTM\n",
        "        self.input_size = 39    # è¿™ä¸€é¡¹æ˜¯RNNçš„\"input_dim\"ï¼ŒRNNéœ€è¦å¯¹\"å•\"ä¸ªæ•°æ®è¿›è¡Œå¤„ç†\n",
        "        self.hidden_size = 512  # è¿™ä¸€é¡¹æ˜¯RNNçš„\"hidden_dim\"\n",
        "        self.num_layers = 6     # è¿™ä¸€é¡¹æ˜¯RNNçš„\"hidden_layers\"\n",
        "        self.rnn = nn.LSTM(input_size=self.input_size, hidden_size=self.hidden_size, num_layers=self.num_layers, batch_first=True, dropout=0.3, bidirectional=True)\n",
        "\n",
        "        # åæ¥å…¨è¿æ¥å±‚\n",
        "        self.fc = nn.Sequential(\n",
        "            # ä¿®æ”¹æˆ 2 * self.hidden_size çš„åŸå› æ˜¯å› ä¸ºLSTM()ä¸­çš„bidirectionalè®¾ç½®ä¸ºäº†Trueï¼Œè¿™è¡¨ç¤ºä½¿ç”¨Biï¼ˆåŒå‘ï¼‰LSTMæ¨¡å‹ï¼Œæ‰€ä»¥éœ€è¦ä¿®æ”¹è¾“å…¥ç»´åº¦ä»¥åŒ¹é…\n",
        "            BasicBlock(2 * self.hidden_size, hidden_dim),\n",
        "            # åœ¨å‡½æ•°çš„è°ƒç”¨ä¸­ï¼Œä¸€ä¸ª * è¡¨ç¤ºå°†ä¸€ä¸ªåºåˆ—å±•å¼€ä¸ºå•ç‹¬çš„ä½ç½®å‚æ•°ï¼Œè¿™ä¸€è¡Œä»£ç æ˜¯åˆ—è¡¨æ¨å¯¼ï¼Œæœ€ç»ˆçš„è¡¨ç°æ˜¯é‡å¤ç”Ÿæˆå¤šä¸ª hidden layer\n",
        "            #ï¼ˆåŸæ¥çš„æ•´æ®µä»£ç å®é™…ä¸Šç”Ÿæˆäº† hidden_layers+1 ä¸ªéšè—å±‚ï¼Œæ‰€ä»¥æˆ‘ä¿®æ”¹äº†ä¸€ä¸‹ä»£ç ï¼Œè®©å…¶ç¬¦åˆå®šä¹‰ï¼‰\n",
        "            *[BasicBlock(hidden_dim, hidden_dim) for _ in range(hidden_layers-1)],\n",
        "            nn.Linear(hidden_dim, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # é€šè¿‡RNNå±‚ï¼Œå¾—åˆ°è¾“å‡ºå’Œæœ€åä¸€ä¸ªéšè—çŠ¶æ€ï¼Œæ³¨æ„è¾“å‡ºçš„shape\n",
        "        # x.shape: (batch_size, seq_len, RNN_input_size)\n",
        "        x, _ = self.rnn(x)  # => (batch_size, seq_len, RNN_hidden_size)\n",
        "\n",
        "        # å–æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡ºä½œä¸ºåˆ†ç±»çš„è¾“å…¥\n",
        "        x = x[:, -1]        # => (batch_size, RNN_hidden_size)\n",
        "\n",
        "        # é€šè¿‡çº¿æ€§å±‚ï¼Œå¾—åˆ°æœ€ç»ˆçš„åˆ†ç±»ç»“æœ\n",
        "        x = self.fc(x)      # => (batch_size, labels)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-20T08:14:28.046310Z",
          "iopub.execute_input": "2025-02-20T08:14:28.046628Z",
          "iopub.status.idle": "2025-02-20T08:14:28.054043Z",
          "shell.execute_reply.started": "2025-02-20T08:14:28.046604Z",
          "shell.execute_reply": "2025-02-20T08:14:28.053023Z"
        },
        "id": "S_d6zMTsW7rR"
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyper-parameters"
      ],
      "metadata": {
        "id": "TlIq8JeqvvHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data prarameters\n",
        "# TODO: change the value of \"concat_nframes\" for medium baseline\n",
        "concat_nframes = 61 #21, 61      # the number of frames to concat with, n must be odd (total 2k+1 = n frames)\n",
        "train_ratio = 0.95           # the ratio of data used for training, the rest will be used for validation\n",
        "\n",
        "# Training parameters\n",
        "seed = 1213                  # random seed\n",
        "batch_size = 512             # batch size\n",
        "num_epoch = 5 # 15               # the number of training epoch\n",
        "learning_rate =  1e-3        # learning rate\n",
        "model_path = './model.ckpt'  # the path where the checkpoint will be saved\n",
        "\n",
        "# Model parameters\n",
        "# TODO: change the value of \"hidden_layers\" or \"hidden_dim\" for medium baseline\n",
        "input_dim = 39 * concat_nframes  # the input dim of the model, you should not change the value\n",
        "hidden_layers = 6            # the number of hidden layers\n",
        "hidden_dim = 1024 #512            # the hidden dim\n",
        "\n",
        "''' ä»¥ä¸‹æ˜¯ä¸ºäº†å®Œæˆ report æ‰€æ·»åŠ çš„ä»£ç  '''\n",
        "# TODO: å®Œæˆ report åæ³¨é‡Šä¸‹é¢æ‰€æœ‰ä»£ç \n",
        "# æå‰è¾“å‡ºæ¨¡å‹å‚æ•°æ•°é‡ï¼Œä»¥ä¾¿è°ƒæ•´ç½‘ç»œæ¶æ„\n",
        "# total_params = (\n",
        "#     (input_dim+1) * hidden_dim +\n",
        "#     (hidden_dim + 1) * hidden_dim * (hidden_layers - 1) +\n",
        "#     (hidden_dim + 1) * 41\n",
        "# )\n",
        "# print(f'Total params: {total_params}')\n",
        "\n",
        "# def get_dest_dim(input_dim, output_dim, hidden_layers, dest_hidden_layers, hidden_dim):\n",
        "#     '''è·å–ç›®æ ‡ç½‘ç»œéšè—å±‚çš„ç»´åº¦ï¼ˆæ€»å‚æ•°é‡æ¥è¿‘äºåŸç½‘ç»œï¼‰'''\n",
        "#     # è®¡ç®—ä¸€å…ƒäºŒæ¬¡æ–¹ç¨‹çš„ç³»æ•° a,b,c\n",
        "#     a = dest_hidden_layers - 1  # a = l_d - 1\n",
        "#     b = input_dim + output_dim + dest_hidden_layers  #  b = i + o + l_d\n",
        "#     c = - (hidden_layers - 1) * (hidden_dim ** 2) - (input_dim + output_dim + hidden_layers) * hidden_dim  # c = - (l - 1) * (d ** 2) - (i + o + l) * d\n",
        "\n",
        "#     # è®¡ç®—åˆ†å­ä¸­çš„å¹³æ–¹æ ¹éƒ¨åˆ†ï¼Œå³ b^2-4ac\n",
        "#     sqrt_part = (b ** 2) - 4 * a * c\n",
        "\n",
        "#     # è®¡ç®—ä¸¤ä¸ªè§£ï¼Œä¸€ä¸ªæ˜¯åŠ å·ï¼Œä¸€ä¸ªæ˜¯å‡å·ï¼Œå³(-bÂ±âˆš(b^2-4ac))/(2a)\n",
        "#     d_d_plus = (-b + sqrt_part**(0.5)) / (2 * a)\n",
        "#     d_d_minus = (-b - sqrt_part**(0.5)) / (2 * a)\n",
        "\n",
        "#     # è¿”å›ä¸¤ä¸ªè§£çš„å…ƒç»„\n",
        "#     return (d_d_plus, d_d_minus)\n",
        "\n",
        "# # è®¾ç½®ä½ æƒ³è¦çš„ç›®æ ‡ç½‘ç»œéšè—å±‚æ•°é‡\n",
        "# dest_hidden_layers = 2\n",
        "\n",
        "# # è·å–å¯¹åº”çš„ç»´æ•°\n",
        "# dest_hidden_dim, _ = get_dest_dim(input_dim, 41, hidden_layers, dest_hidden_layers, hidden_dim)\n",
        "# print(f\"è‹¥å°†éšè—å±‚ç½‘ç»œå±‚æ•°æ”¹ä¸º: {dest_hidden_layers}ï¼Œåˆ™ç»´æ•°åº”å½“æ”¹ä¸º: {round(dest_hidden_dim)}\",)"
      ],
      "metadata": {
        "id": "iIHn79Iav1ri",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-20T08:14:34.525568Z",
          "iopub.execute_input": "2025-02-20T08:14:34.525913Z",
          "iopub.status.idle": "2025-02-20T08:14:34.532322Z",
          "shell.execute_reply.started": "2025-02-20T08:14:34.525885Z",
          "shell.execute_reply": "2025-02-20T08:14:34.531519Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "85b51da3-c342-4276-fc95-17d1e9f339a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' ä»¥ä¸‹æ˜¯ä¸ºäº†å®Œæˆ report æ‰€æ·»åŠ çš„ä»£ç  '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataloader"
      ],
      "metadata": {
        "id": "IIUFRgG5yoDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import gc\n",
        "\n",
        "same_seeds(seed)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'DEVICE: {device}')\n",
        "\n",
        "# Preprocess data\n",
        "train_X, train_y = preprocess_data(split='train', feat_dir='./libriphone/feat', phone_path='./libriphone', concat_nframes=concat_nframes, train_ratio=train_ratio, random_seed=seed)\n",
        "val_X, val_y = preprocess_data(split='val', feat_dir='./libriphone/feat', phone_path='./libriphone', concat_nframes=concat_nframes, train_ratio=train_ratio, random_seed=seed)\n",
        "\n",
        "# Get dataset\n",
        "train_set = LibriDataset(train_X, train_y)\n",
        "val_set = LibriDataset(val_X, val_y)\n",
        "\n",
        "# Remove raw feature to save memory\n",
        "del train_X, train_y, val_X, val_y\n",
        "gc.collect()\n",
        "\n",
        "# Get dataloader\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "c1zI3v5jyrDn",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-20T08:14:42.873417Z",
          "iopub.execute_input": "2025-02-20T08:14:42.873779Z",
          "iopub.status.idle": "2025-02-20T08:15:16.302674Z",
          "shell.execute_reply.started": "2025-02-20T08:14:42.873746Z",
          "shell.execute_reply": "2025-02-20T08:15:16.302012Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f48b16cd-ac79-4b57-b87e-d22382b43b16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEVICE: cuda\n",
            "[Dataset] - # phone classes: 41, number of utterances for train: 4071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]<ipython-input-3-b47e0bf89eaa>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  feat = torch.load(path)\t# å¯¼å…¥éŸ³é¢‘æ–‡ä»¶\n",
            "4071it [00:22, 178.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] train set\n",
            "torch.Size([2510111, 2379])\n",
            "torch.Size([2510111])\n",
            "[Dataset] - # phone classes: 41, number of utterances for val: 215\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "215it [00:01, 179.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] val set\n",
            "torch.Size([134047, 2379])\n",
            "torch.Size([134047])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "pwWH1KIqzxEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## For plotting learning curve\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "writer = SummaryWriter() # Tensorboard ç”»å›¾ï¼Œç»“æœå­˜å‚¨åœ¨ ./runs ä¸­\n",
        "\n",
        "RESUME = True  # æ˜¯å¦å¯¼å…¥æ¨¡å‹ç»§ç»­è·‘ï¼ˆåœ¨ä½ ä¸å°å¿ƒä¸­æ–­äº†å†…æ ¸åï¼‰\n",
        "\n",
        "# Create a model, and put it on the device specified.\n",
        "model = Classifier(input_dim=input_dim, hidden_layers=hidden_layers, hidden_dim=hidden_dim).to(device)\n",
        "\n",
        "if RESUME:\n",
        "    # model.load_state_dict(torch.load(\"../input/hw2-model/model.ckpt\", map_location='cuda')) # kaggle\n",
        "    model.load_state_dict(torch.load(\"/content/model.ckpt\", map_location='cuda'))\n",
        "\n",
        "# Define a loss function, and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Create a learning rate scheduler\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.8, patience=5, threshold=0.05) # 5 è½®æ²¡æœ‰ä¼˜åŒ–ï¼ˆå¢é•¿ç‡ < threshold)å°±ä»¤ lr *= factor\n",
        "\n",
        "best_acc = 0.0\n",
        "for epoch in range(num_epoch):\n",
        "    train_acc = 0.0\n",
        "    train_loss = 0.0\n",
        "    val_acc = 0.0\n",
        "    val_loss = 0.0\n",
        "\n",
        "    # ---------- Training ----------\n",
        "    # Make sure the model is in train mode before training.\n",
        "    model.train()\n",
        "\n",
        "    for i, batch in enumerate(tqdm(train_loader)):\n",
        "\n",
        "        # A batch consists of features data and corresponding labels.\n",
        "        features, labels = batch  # feature.shape: (batch_size, seq_len * input_size)\n",
        "\n",
        "        # Forward the data. (Make sure data and model are on the same device.)\n",
        "        # features = features.to(device)\n",
        "        # TODO: RNNåˆ™å–æ¶ˆæ³¨é‡Šä¸‹è¡Œ\n",
        "        features = features.view(-1, concat_nframes, 39).to(device) # feature.shape: (batch_size, seq_len, input_size)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(features) # (batch_size, labels)\n",
        "\n",
        "        # Calculate the cross-entropy loss.\n",
        "        # We don't need to apply softmax before computing cross-entropy as it is done automatically.\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Gradients stored in the parameters in the previous step should be cleared out first.\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Compute the gradients for parameters.\n",
        "        loss.backward()\n",
        "\n",
        "        # Update the parameters with computed gradients.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Get the index of the class with the highest probability\n",
        "        _, train_pred = torch.max(outputs, 1)\n",
        "\n",
        "        # Compute the accuracy for current batch.\n",
        "        train_acc += (train_pred.detach() == labels.detach()).sum().item()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    # ---------- Validation ----------\n",
        "    # Make sure the model is in eval mode so that some modules like dropout are disabled and work normally.\n",
        "    model.eval()\n",
        "\n",
        "    # We don't need gradient in validation.\n",
        "    # Using torch.no_grad() accelerates the forward process.\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(tqdm(val_loader)):\n",
        "            features, labels = batch\n",
        "            # features = features.to(device)\n",
        "            # TODO: RNNåˆ™å–æ¶ˆæ³¨é‡Šä¸‹è¡Œ\n",
        "            features = features.view(-1, concat_nframes, 39).to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(features)\n",
        "\n",
        "            # We can still compute the loss (but not the gradient).\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Get the index of the class with the highest probability\n",
        "            _, val_pred = torch.max(outputs, 1)\n",
        "\n",
        "            # Compute the accuracy for current batch.\n",
        "            val_acc += (val_pred.cpu() == labels.cpu()).sum().item()\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    # Record the accuracy and lr.\n",
        "    writer.add_scalar('Acc/train', train_acc/len(train_set), epoch)\n",
        "    writer.add_scalar('Acc/valid', val_acc/len(val_set), epoch)\n",
        "    writer.add_scalar('lr', optimizer.state_dict()['param_groups'][0]['lr'], epoch)\n",
        "\n",
        "    # Print the information.\n",
        "    print(f'[{epoch+1:03d}/{num_epoch:03d}] Train Acc: {train_acc/len(train_set):3.5f} Loss: {train_loss/len(train_loader):3.5f} | Val Acc: {val_acc/len(val_set):3.5f} loss: {val_loss/len(val_loader):3.5f}')\n",
        "\n",
        "    # If the model improves, save a checkpoint at this epoch\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "        print(f'saving model with acc {best_acc/len(val_set):.5f}')\n",
        "\n",
        "    print(f\"{epoch+1} lr: {optimizer.state_dict()['param_groups'][0]['lr']}\")\n",
        "\n",
        "    # Update learning rate based on best loss\n",
        "    # Modify step() according to your scheduler\n",
        "    scheduler.step(val_acc/len(val_set))\n",
        "\n",
        "print(f'saving model with acc {best_acc/len(val_set):.5f}')\n"
      ],
      "metadata": {
        "id": "CdMWsBs7zzNs",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-20T08:15:21.943638Z",
          "iopub.execute_input": "2025-02-20T08:15:21.943968Z",
          "iopub.status.idle": "2025-02-20T08:15:57.979416Z",
          "shell.execute_reply.started": "2025-02-20T08:15:21.943945Z",
          "shell.execute_reply": "2025-02-20T08:15:57.978138Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77ce42ea-991b-4dee-83d4-d9ce23bd2abd"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-11-ca26ea5e6eb4>:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"/content/model.ckpt\", map_location='cuda'))\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4903/4903 [08:57<00:00,  9.11it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 262/262 [00:09<00:00, 27.65it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[001/005] Train Acc: 0.93913 Loss: 0.17080 | Val Acc: 0.81962 loss: 0.99753\n",
            "saving model with acc 0.81962\n",
            "1 lr: 0.001\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4903/4903 [08:56<00:00,  9.14it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 262/262 [00:09<00:00, 28.27it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[002/005] Train Acc: 0.93795 Loss: 0.17415 | Val Acc: 0.82095 loss: 0.99449\n",
            "saving model with acc 0.82095\n",
            "2 lr: 0.001\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4903/4903 [08:56<00:00,  9.14it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 262/262 [00:09<00:00, 28.48it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[003/005] Train Acc: 0.93915 Loss: 0.17005 | Val Acc: 0.82340 loss: 1.00099\n",
            "saving model with acc 0.82340\n",
            "3 lr: 0.001\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4903/4903 [08:56<00:00,  9.14it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 262/262 [00:09<00:00, 28.42it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[004/005] Train Acc: 0.93951 Loss: 0.16911 | Val Acc: 0.82150 loss: 0.96015\n",
            "4 lr: 0.001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4903/4903 [08:56<00:00,  9.13it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 262/262 [00:09<00:00, 27.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[005/005] Train Acc: 0.74986 Loss: 0.87042 | Val Acc: 0.68219 loss: 1.19360\n",
            "5 lr: 0.001\n",
            "saving model with acc 0.82340\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir=./runs/"
      ],
      "metadata": {
        "id": "5uiXX1ZnW7rW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "del train_set, val_set\n",
        "del train_loader, val_loader\n",
        "gc.collect()"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-07T10:18:47.085697Z",
          "start_time": "2023-04-07T10:18:47.065320Z"
        },
        "id": "ab33MxosWLmG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0616990-2f9f-4a3f-d57b-d634b8367748"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "execution_count": 12
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing\n",
        "Create a testing dataset, and load model from the saved checkpoint."
      ],
      "metadata": {
        "id": "1Hi7jTn3PX-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "test_X = preprocess_data(split='test', feat_dir='./libriphone/feat', phone_path='./libriphone', concat_nframes=concat_nframes)\n",
        "test_set = LibriDataset(test_X, None)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "VOG1Ou0PGrhc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fc6fa97-a875-48f2-c3a9-bf2a229350dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Dataset] - # phone classes: 41, number of utterances for test: 1078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]<ipython-input-3-b47e0bf89eaa>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  feat = torch.load(path)\t# å¯¼å…¥éŸ³é¢‘æ–‡ä»¶\n",
            "1078it [00:06, 164.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] test set\n",
            "torch.Size([646268, 2379])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "source": [
        "# load model\n",
        "model = Classifier(input_dim=input_dim, hidden_layers=hidden_layers, hidden_dim=hidden_dim).to(device)\n",
        "model.load_state_dict(torch.load(model_path))"
      ],
      "metadata": {
        "id": "ay0Fu8Ovkdad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f437411b-3689-42c5-cc0c-41a3a996453d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-f7b7612de35f>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "execution_count": 14
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make prediction."
      ],
      "metadata": {
        "id": "zp-DV1p4r7Nz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred = np.array([], dtype=np.int32)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for i, batch in enumerate(tqdm(test_loader)):\n",
        "        features = batch\n",
        "        # features = features.to(device)\n",
        "        features = features.view(-1, concat_nframes, 39).to(device)\n",
        "\n",
        "        outputs = model(features)\n",
        "\n",
        "        _, test_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n",
        "        pred = np.concatenate((pred, test_pred.cpu().numpy()), axis=0)\n"
      ],
      "metadata": {
        "id": "84HU5GGjPqR0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc44c9a7-8e96-4ac1-a56f-64644d384806"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1263/1263 [00:42<00:00, 29.71it/s]\n"
          ]
        }
      ],
      "execution_count": 15
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write prediction to a CSV file.\n",
        "\n",
        "After finish running this block, download the file `prediction.csv` from the files section on the left-hand side and submit it to Kaggle."
      ],
      "metadata": {
        "id": "wyZqy40Prz0v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('prediction.csv', 'w') as f:\n",
        "    f.write('Id,Class\\n')\n",
        "    for i, y in enumerate(pred):\n",
        "        f.write('{},{}\\n'.format(i, y))"
      ],
      "metadata": {
        "id": "GuljYSPHcZir"
      },
      "outputs": [],
      "execution_count": 16
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YIBz71I8W7rZ"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}